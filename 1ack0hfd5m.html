<h2 data-label="933181" class="ltx_title_subsection">Aggregating Citizen Scientist Ratings to Emulate  Expert Labels</h2><div><b>Citizen scientists who rated images through braindr differed substantially in terms of how well their ratings match the experts ratings: while some agree with the experts most of the time, others disagree with them for a substantial portion of the brain slices rated. To create image labels that more closely match the expert opinion, we assigned a weight to each citizen scientist based on their match to expert agreement in slices from the gold-standard set. We used the XGBoost algorithm&nbsp;</b>&nbsp;<cite class="ltx_cite raw v1">\cite{Chen2016}</cite>, <b>an ensemble method that combines a set of weak learners (decision trees) to fit the “gold” standard labels based on a set of features. In our case, the features were the average rating of the slice image from each rater (some images were viewed and rated more than once, so image ratings could vary between 1=always “pass” and 0=always “fail”). We could then use the rater weights to predict on the left out test set.</b> Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>A <b>shows ROC curves of classification on the left-out test set for different training set sizes, compared to the ROC curve of a baseline model in which equal weights were assigned to each citizen scientist. We see a slight improvement in the AUC of the XGBoosted labels (0.97) compared to the AUC of the equi-weighted &nbsp;labels (0.95). Using the model trained on two-thirds of the gold standard data (n=670 slices), we extracted the probability scores of the classifier on all slices</b> (see Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>B). <b>The distribution of probability scores in Figure&nbsp;???B matches our expectations of the data; a bimodal distribution with peaks at 0 and 1, reflecting that images are mostly perceived as “passing” or “failing” . The XGBoost model also calculates a feature importance score (F). F is the number of times that feature (in our case, individual citizen scientist) has split the branches of a tree, summed over all boosted trees. </b> Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>C <b>shows the a relationship between a rater’s importance compared to the number of images they rated. In general, the more number of images a user rates, the more important they are to the model. However, there are still a few exceptions where a rater scored many images, but were incorrect, so the model gave their ratings less weight during aggregation.</b>&nbsp;</div>