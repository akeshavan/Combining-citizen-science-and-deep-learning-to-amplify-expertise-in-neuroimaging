<h2 data-label="933181" class="ltx_title_subsection">Aggregating Citizen Scientist Ratings to Emulate  Expert Labels</h2><div>Citizen scientists who rated images through the interactive web application differed substantially in terms of how well their ratings match the experts ratings: while some agree with the experts most of the time, others disagree with them for a substantial portion of the brain slices rated. To create image lthat more closely match the expert opinion, we assigned a weight to each citizen scientist. We used the XGBoost algorithm&nbsp;<cite class="ltx_cite raw v1">\cite{Chen2016}</cite>, an ensemble method that combines a set of weak learners (decision trees) to predict the "gold" standard labels based on a set of features. In our case, the features were  the average rating of the image from each rater. We defined the XGBoosted labels as the probability score of the trained XGBoost model's classification. Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>A shows various ROC curves of the left out test set for different  training set sizes, compared to the ROC curve of the average rating. We see a slight improvement in the AUC of the XGBoosted labels (0.97) compared to the AUC of the average labels (0.95). Using the model trained on two-thirds of the data (n=670), we extracted the probability scores of the classifier on all  slices in braindr (see Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>B). The distribution of probability scores in Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>B matches our expectations of the data; a bimodal distribution with peaks at 0 and 1. The XGBoost model also calculates a feature importance score (F). F is the number of times that feature (in our case, rater) has split the branches of a tree, summed over all boosted trees. Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>C shows the feature importance  for each rater. Figure&nbsp;<span class="au-ref raw v1">\ref{468392}</span>D shows the a relationship between a rater's importance compared to the number of images they rated. In general, the more number of images a user rates, the more important they are to the model. However, there are still a few exceptions where a rater scored many images, but were incorrect, so the model gave their ratings less weight during aggregation.&nbsp;</div>