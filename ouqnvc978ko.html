<h2 data-label="152075" class="ltx_title_subsection">Training Deep Learning to Automate Image Labeling</h2><div><b>The deep learning model was trained to predict the XGBoosted labels that were based on citizen scientist ratings.&nbsp;A VGG16 neural network</b>&nbsp;<cite class="ltx_cite raw v1">\cite{simonyan2014very}</cite>, pretrained on the ImageNet challenge dataset was used: we removed the top layer of the network, and then trained&nbsp; a final fully-connected layer followed by a single node output layer. The training of the final layer was run for 50 epochs and the best model on the validation set was saved. To estimate the variability of our the variability of the results of training, &nbsp;the model was trained through 10 different training  courses, each time with a different random initialization seed. Typically, training and validation loss scores were equal at around 10 epochs, after which the model usually began to overfit (training error decreased, while validation error increased). In each of the 10 training courses, we used the model with the lowest validation error &nbsp;for inference on the held out test set, and calculated the ROC AUC. AUC may be a problematic statistic when the test-set is imbalanced (CITE), but in this case, the test-set is almost perfectly balanced (see Methods). We found that a deep learning network trained on citizen scientist generated labels matched closer to expert ratings than citizen scientist generated labels alone: the deep learning model had an &nbsp;AUC of 0.99 (+/- standard deviation of 0.12).</div>