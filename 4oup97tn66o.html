<h1 data-label="408498" class="ltx_title_section">Discussion</h1><div>We have developed a system to scale expertise in brain MRI quality control through citizen science amplification combined with deep learning (via CNNs). We have validated our method against MRIQC, a specialized tool that already exists for this particular use&nbsp;<cite class="ltx_cite raw v1">\cite{Esteban2017}</cite>. Unlike MRIQC, our method is able to generalize beyond the classification of T1-weighted images; any image-based binary classification task can be loaded onto the Braindr platform, and crowdsourced via the web. We have also demonstrated the importance of scaling QC expertise  by showing how replication of a previously established result on gray matter volume over time during development&nbsp;<cite class="ltx_cite raw v1">\cite{Lebel2011}</cite>, depends on a researcher's decision on data quality. In the following sections, we discuss in more depth the various concepts that are related to this work; in particular we 1) discuss the impact of the internet and web-applications for collaboration, 2) review research on MRI quality control and morphometrics over brain development, 3) discuss limitations of our method, and 4) propose future directions.&nbsp;</div><div></div><h2 data-label="240928" class="ltx_title_subsection">The Internet and Web Applications for Collaboration&nbsp;</h2><div>The internet and web browser are not only crucial for scientific communication, but also for collaboration and distribution of work. Recent efforts in citizen science projects for neuroscience research have proven extremely useful and popular, in part due to the ubiquity of the web browser. Large scale web-based citizen science projects, like EyeWire&nbsp;<cite class="ltx_cite raw v1">\cite{kim2014space,marx2013neuroscience}</cite>&nbsp;and Mozak&nbsp;<cite class="ltx_cite raw v1">\cite{roskams2016power}</cite>&nbsp;have enabled scientists working with high resolution microscopy data to map neuronal connections at the microscale with help from over 100,000 citizen scientists. In MR imaging,&nbsp; web-based  tools such as&nbsp;BrainBox&nbsp;<cite class="ltx_cite raw v1">\cite{heuer2016open}</cite>&nbsp;and Mindcontrol&nbsp;<cite class="ltx_cite raw v1">\cite{Keshavan2017}</cite>&nbsp;were built to facilitate the collaboration  of neuroimaging experts in image segmentation and quality control. However, the task of inspecting each slice of a 3D image in either BrainBox or Mindcontrol takes too long, and this complex task tends to lose potential citizen scientists who find it too difficult or time consuming.&nbsp; &nbsp;</div><div></div><div>In order to simplify the task for citizen scientists, we developed a web application called braindr&nbsp;<cite class="ltx_cite raw v1">\cite{keshavan2018}</cite>, which reduces the time-consuming task of slice-by-slice 3D inspection to a quick decision made on a 2D slice. Using braindr, citizen scientists amplified the initial expert-labelled dataset ( 200 3D images) to the entire dataset (&gt; 700 3D images, &gt; 3000 2D slices) in a very short time. Because braindr is a lightweight web application, users could play it at any time and on any device, and this meant we were able to attract many users. On braindr, each slice received on average 20 ratings, and therefore each 3D brain (consisting of 5 slices) received 100 ratings.  In short, by redesigning the way we interact with our data and presenting it on the web browser, we were able to get many more eyes on our data than would have been possible in a single research lab.</div><div></div><h2 data-label="638082" class="ltx_title_subsection">MRI Quality Control and Morphometrics over Development</h2><div>Recently, Ducharme and colleagues&nbsp;<cite class="ltx_cite raw v1">\cite{Ducharme2016}</cite> stressed the importance of quality control on brain morphometry studies in development in a large study of 954 subjects. They estimated cortical thickness on each point of a cortical surface and fit linear, quadratic and cubic models of thickness versus age at each vertex. Quality control was performed by visual inspection of the reconstructed cortical surface, and removing data that failed QC from the analysis. Without stringent quality control, the best fit models were more complex (quadratic/cubic), and with quality control the best fit models were linear. They found sex differences only at the occipital regions, which thinned faster in males. In Figure&nbsp;<span class="au-ref raw v1">\ref{612467}</span>, we presented an interactive chart where users can similarly explore different ordinary least squares models (linear or quadratic) and also split by sex for the relationship between total gray matter volume, white matter volume, CSF volume, and total brain volume over age. One possible future direction of this work is to create 2D images of cortical surfaces to QC via the braindr application, in order to replicate the results of Ducharme and colleagues.&nbsp;</div><div></div><div>We chose to QC  raw MRI data in this study, rather than the processed data because the quality of the raw MRI data affects the downstream cortical mesh generation, and many other computed metrics. A large body of research in automated QC of T1-weighted&nbsp;images exists, in part because of large open data sharing initiatives.&nbsp; In 2009, Mortamet and colleagues&nbsp;<cite class="ltx_cite raw v1">\cite{mortamet2009automatic}</cite> developed a QC algorithm based on the background of magnitude images of the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset, and reported a sensitivity and specificity of &gt; 85%. In 2015, Shezad and colleagues&nbsp;<cite class="ltx_cite raw v1">\cite{shehzadpreprocessed}</cite>&nbsp;developed the Preprocessed Connectomes Project Quality Assessment Protocol (PCP-QAP)&nbsp; on the Autism Brain Imaging Data Exchange (ABIDE) and Consortium for Reproducibility and Reliability (CoRR) datasets. The PCP-QAP also included a Python library to easily compute metrics such as signal to noise ratio, contrast to noise ratio, entropy focus criterion, foreground-to-background energy ratio, voxel smoothness, and percentage of artifact voxels. Building on this work, the MRIQC package from Esteban and colleagues&nbsp;&nbsp;<cite class="ltx_cite raw v1">\cite{Esteban2017a}</cite> includes a comprehensive set of 64 image quality metrics, from which a classifier was trained to predict data quality of the ABIDE dataset for new, unseen sites with 76% accuracy.&nbsp;</div><div></div><div>Our strategy differed from that of the MRIQC classification study. In&nbsp;<cite class="ltx_cite raw v1">\cite{Esteban2017a}</cite>, the authors labelled images that were "doubtful" in quality as a "pass" when training and evaluating their classifier. Our MRIQC classifier was trained and evaluated only on images that our raters&nbsp;very confidently passed or failed. Because quality control is  subjective, we felt that it was acceptable for a "doubtful" image to be failed by the classifier. Since our classifier was trained on data acquired within a single site, and only on images that we were confident about, our MRIQC classifier achieved near perfect accuracy with an AUC of 0.99. On the other hand, our braindr CNN was trained as a regression (rather than a classification) on the full dataset, including the "doubtful" images (i.e those with ratings closer to 0.5), but was still evaluated as a classifier against data we were confident about. This also achieved near-perfect accuracy with an AUC of 0.99. Because both the MRIQC and braindr classifiers perform so well on data we are confident about, we contend that it is acceptable to let the classifier act as a "tie-breaker" for images that lie in the middle of the spectrum, for all future acquisitions of the HBN dataset.&nbsp;</div><div></div><h2 data-label="679893" class="ltx_title_subsection">Limitations</h2><div>One limitation of this method is that there is an interpretability to speed tradeoff. Specialized QC tools were developed over many years, while this study was performed in a matter of months. But specialized QC tools are more interpretable; for example, the coefficient of joint variation (C metric from MRIQC</div><ul><li></li><li>citizen scientists were primarily neuroscientists</li><li>still, a tendency for false positives</li><li>to extend beyond neuroimagers, need better tutorials in the vein of eye wire</li></ul><div></div><h2 data-label="404417" class="ltx_title_subsection">Future Directions</h2><ul><li>Integration with existing citizen science projects</li><li>Implementing other classification tasks that don't have algs (ICA components)</li><li>Integration with existing open data initiatives (open neuro)</li></ul><div></div><h1 data-label="986206" class="ltx_title_section">Methods</h1><div></div><div></div>