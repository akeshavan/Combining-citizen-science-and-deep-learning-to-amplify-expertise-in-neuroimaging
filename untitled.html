<div></div><h1 data-label="712766" class="ltx_title_section">Introduction</h1><div>Human neuroscience&nbsp;has entered an era of “Big Data”&nbsp;<cite class="ltx_cite raw v1">\cite{Van_Horn_2013}</cite>:&nbsp; the assembly of large aggregated datasets, or large datasets containing measurements from many individuals, collected through consortium efforts, such as the Human Connectome Project promise to enhance our understanding&nbsp; of the relationship between brain anatomy and cognition. The field is experiencing a “paradigm shift”&nbsp;<cite class="ltx_cite raw v1">\cite{Fan_2014}</cite>, where our once established scientific procedures are morphing, as dictated by the new challenges posed by large datasets.&nbsp;We’ve seen a shift from desktop computers to cyberinfrastructure&nbsp;<cite class="ltx_cite raw v1">\cite{Van_Horn_2013}</cite>, from small studies siloed in individual labs to an explosion of data sharing initiatives&nbsp;<cite class="ltx_cite raw v1">\cite{Ferguson_2014,Poldrack_2014}</cite>, and an overall shift in statistical thinking and computational methods&nbsp;<cite class="ltx_cite raw v1">\cite{Fan2014}</cite> that can accommodate large datasets.&nbsp;But one, often overlooked, aspect of our scientific protocols in neuroimaging has not yet evolved to the needs of Big Data: expert decision making.&nbsp;</div><div></div><div><b>Many research fields ranging from astronomy, to genomics, to neuroscience are entering an era of “Big Data”. Large and complex datasets promise to address many scientific questions, but they also present a new set of challenges. For example, over the last few years human neuroscience&nbsp;has evolved into a “Big Data” field. In the past, individual groups would each collect their own relatively small samples of data from a limited group individuals. More recently, large data sets collected from many thousands of individuals are increasingly more common. This transition has been facilitated through &nbsp;assembly of large aggregated datasets, containing measurements from many individuals, and collected through consortium efforts such as the Human Connectome Project. These efforts, and the large datasets that they are assembling promise to enhance our understanding&nbsp; of the relationship between brain anatomy, brain activity and cognition. The field is experiencing a “paradigm shift”&nbsp;(Fan, Han, and Liu 2014), where our once established scientific procedures are morphing as dictated by the new challenges posed by large datasets.&nbsp;We’ve seen a shift from desktop computers to cyberinfrastructure&nbsp;(Van Horn and Toga 2013), from small studies siloed in individual labs to an explosion of data sharing initiatives&nbsp;(Ferguson et al. 2014; Poldrack and Gorgolewski 2014), and an overall shift in statistical thinking and computational methods&nbsp;(Fan, Han, and Liu 2014) that can accommodate large datasets.&nbsp;But one often overlooked aspect of our protocols in neuroimaging has not yet evolved to the needs of Big Data: expert decision making.&nbsp;</b></div><div></div><div>Specifically, decisions made by neuroimaging experts through visual inspection of imaging data cannot be reliably scaled to large datasets.&nbsp;These are decisions made by those with experience in imaging and neuroanatomy, like tracing of regions of interest (ROIs), the editing of fascicle models from streamline tractography&nbsp;<cite class="ltx_cite raw v1">\cite{Jordan_2017}</cite>, the evaluation of cross-modality image alignment, and quality control of images at each stage of processing.&nbsp;On large datasets, especially longitudinal multisite consortium studies, these expert decisions cannot be reliably replicated because the timeframe of these studies is long, and individual experts get fatigued. As datasets grow to hundreds of thousands of brains it is no longer feasible to depend on manual interventions.</div><div></div><div>One solution to this issue is to train machines to emulate experts’ decisions, but there are many cases in which even where automated algorithms exist, expert decision-making is still required for optimal results. For example, a variety of image segmentation algorithms have been developed to replace manual ROI editing, with Freesurfer&nbsp;<cite class="ltx_cite raw v1">\cite{fischl2012freesurfer}</cite>, FSL&nbsp;<cite class="ltx_cite raw v1">\cite{Patenaude_2011}</cite>, ANTS&nbsp;<cite class="ltx_cite raw v1">\cite{Avants_2011}</cite>, and SPM&nbsp;<cite class="ltx_cite raw v1">\cite{Ashburner_2005}</cite> all offering automated segmentation tools for standard structures. But these algorithms were developed on a specific type of image (T1-weighted) and on a specific type of brain (those of healthy controls). Pathological brains, or those of children or the elderly may violate the assumptions of these algorithms, and their outputs often require manual expert editing anyway. Similarly, in tractography, a set of anatomical ROIs can be used to target or constrain streamlines to automatically extract fascicles of interest&nbsp;<cite class="ltx_cite raw v1">\cite{CATANI_2008}</cite>.&nbsp;But again, abnormal brain morphometry resulting from pathology would still require expert editing&nbsp;<cite class="ltx_cite raw v1">\cite{Jordan_2017a}</cite>.&nbsp; The delineation of retinotopic maps in visual cortex is another task that has been recently automated&nbsp;<cite class="ltx_cite raw v1">\cite{Benson2014,Benson2012}</cite>, but these procedures are limited to only a few of the known retinotopic maps and substantial expertise is still required to delineate the other known maps&nbsp;<cite class="ltx_cite raw v1">\cite{Winawer2017,Wandell2011}</cite>. Finally, one of the first steps of image processing pipelines is quality assurance/quality control: there are several automated methods to quantify image quality, based on MRI physics and the statistical properties of images, and these have been collected under one umbrella in an algorithm called MRIQC&nbsp;<cite class="ltx_cite raw v1">\cite{Esteban2017}</cite>, but these methods are specific to T1-weighted images, and cannot generalize to different image acquisition methods. To address all of these cases, we need a general-purpose framework that can train machines to emulate experts for any purpose.&nbsp;</div><div></div><div>Deep learning via convolutional neural networks (CNNs) has shown promise in a variety of biomedical image processing tasks. Modeled loosely on the human visual system, CNNs can be trained for a variety of image classification and segmentation tasks using the same architecture. For example, the U-Net&nbsp;<cite class="ltx_cite raw v1">\cite{ronneberger2015u}</cite>&nbsp;which was originally built for segmentation of neurons in electron microscope images, has also been adapted to segment macular edema in optical coherence tomography images&nbsp;<cite class="ltx_cite raw v1">\cite{Lee_2017}</cite>, to segment breast and fibroglandular tissue&nbsp;<cite class="ltx_cite raw v1">\cite{Dalm__2017}</cite>, and a 3D adaptation was developed to segment the&nbsp;<i>Xenopu</i>s kidney&nbsp;<cite class="ltx_cite raw v1">\cite{cciccek20163d}</cite>.&nbsp;</div>