<div></div><h1 data-label="712766" class="ltx_title_section">Introduction</h1><div>The neuroimaging field has entered an era of “Big Data”&nbsp;<cite class="ltx_cite raw v1">\cite{Van_Horn_2013}</cite>:&nbsp; the assembly of large aggregated datasets, or large datasets containing measurements from many individuals, collected through consortium efforts, such as the Human Connectome Project promise to enhance our understanding&nbsp; of the relationship between brain anatomy and brain activity. The field is experiencing a “paradigm shift”&nbsp;<cite class="ltx_cite raw v1">\cite{Fan_2014}</cite>, where our once established scientific procedures are morphing, as dictated by the new challenges posed by large datasets.&nbsp;We’ve seen a shift from desktop computers to cyberinfrastructure&nbsp;<cite class="ltx_cite raw v1">\cite{Horn2013}</cite>, from small studies siloed in individual labs to an explosion of data sharing initiatives&nbsp;<cite class="ltx_cite raw v1">\cite{Ferguson_2014,Poldrack_2014}</cite>, and an overall shift in statistical thinking and computational methods&nbsp;<cite class="ltx_cite raw v1">\cite{Fan2014}</cite> that can acommodate large datasets.&nbsp;But one, often overlooked, aspect of our scientific protocols in neuroimaging has not yet evolved to the needs of Big Data: expert decision making.&nbsp;</div><div></div><div>Specifically, neuroimaging expert decisions made through visual inspection of the data that are not (yet) automated cannot be reliably scaled to large datasets.&nbsp;These are decisions made by those with experience in imaging and neuroanatomy, like tracing of regions of interest (ROIs), the editing of fascicle models from streamline tractography&nbsp;<cite class="ltx_cite raw v1">\cite{Jordan_2017}</cite>, the evaluation of cross-modality image alignment, and quality control of images at each stage of processing.&nbsp;On large datasets, especially longitudinal multisite consortium studies, these expert decisions cannot be reliably replicated because the timeframe of these studies is long, and individual experts get fatigued.</div><div></div><div>One solution to this issue is to train machines to emulate experts’ decisions. A variety of image segmentation algorithms have been developed to replace manual ROI editing, with Freesurfer&nbsp;<cite class="ltx_cite raw v1">\cite{fischl2012freesurfer}</cite>, FSL<cite class="ltx_cite raw v1">\cite{Patenaude_2011}</cite>, ANTS&nbsp;<cite class="ltx_cite raw v1">\cite{Avants_2011}</cite>, and SPM&nbsp;<cite class="ltx_cite raw v1">\cite{Ashburner_2005}</cite> all offering automated segmentation tools for standard structures. But these algorithms were developed on a specific type of image (T1-weighted) and on a specific type of brain (those of healthy controls). Pathological brains, or those of children or the elderly may violate algorithmic assumptions, and their outputs require manual, expert editing anyway. Similarly in tractography, a set of anatomical ROIs can be used to target or constrain streamlines to automatically extract fascicles of interest&nbsp;<cite class="ltx_cite raw v1">\cite{CATANI_2008}</cite>.&nbsp;But again, abnormal brain morphometry resulting from pathology would still require expert intervention&nbsp;<cite class="ltx_cite raw v1">\cite{Jordan_2017a}</cite>.&nbsp;An automated algorithm to quantify image quality, based on MRI physics and the statistical properties of images has been developed, called MRIQC&nbsp;<cite class="ltx_cite raw v1">\cite{Esteban2017}</cite>, but these algorithms are specific to T1-weighted images, and cannot generalize to other image modalities.&nbsp;We  need &nbsp;a more general purpose framework that can train machines to emulate experts for any purpose.</div><div></div><div>Deep learning via convolutional neural networks (CNNs) have shown promise to generalize to various tasks in biomedical imaging. Modeled loosely on the human visual system, CNNs can be trained for a variety of image classification and segmentation tasks using the same  architecture. For example, the U-Net&nbsp;<cite class="ltx_cite raw v1">\cite{ronneberger2015u}</cite>&nbsp;which was originally built for segmentation of neurons from electron microscope images, has also been adapted to segment  macular edema in optical coherence tomography images&nbsp;<cite class="ltx_cite raw v1">\cite{Lee_2017}</cite>, to segment breast and fibroglandular tissue&nbsp;<cite class="ltx_cite raw v1">\cite{Dalm__2017}</cite>, and a 3D adaptation was developed to segment the&nbsp;<i>Xenopu</i>s kidney&nbsp;<cite class="ltx_cite raw v1">\cite{cciccek20163d}</cite>.&nbsp;</div>