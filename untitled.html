<div></div><h1 data-label="712766" class="ltx_title_section">Introduction</h1><div>In order to truly understand the relationship between brain anatomy and brain activity, the neuroimaging field has entered an era of “Big Data”&nbsp;<cite class="ltx_cite raw v1">\cite{Van_Horn_2013}</cite>.&nbsp;With it, the field is experiencing a “paradigm shift”&nbsp;<cite class="ltx_cite raw v1">\cite{Fan_2014}</cite>, where our once established scientific procedures are morphing, as dictated by the new challenges posed by large datasets.&nbsp;We’ve seen a shift from desktop computers to cyberinfrastructure&nbsp;<cite class="ltx_cite raw v1">\cite{Horn2013}</cite>, from small studies siloed in individual labs to an explosion of data sharing initiatives <cite class="ltx_cite raw v1">\cite{Ferguson_2014,Poldrack_2014}</cite>, and an overall shift in statistical thinking and computational methods <cite class="ltx_cite raw v1">\cite{Fan2014}</cite> that can accomodate large datasets.&nbsp;But one, often overlooked, aspect of our scientific protocols in neuroimaging has not yet evolved to the needs of Big Data: expert decision making. </div><div></div><div>Specifically, neuroimaging expert decisions made through visual inspection of the data that are not (yet) automated cannot be reliably scaled to large datasets.&nbsp;These are decisions made by those with experience in imaging and neuroanatomy, like tracing of regions of interest (ROIs), the editing of fascicle models from streamline tractography&nbsp;<cite class="ltx_cite raw v1">\cite{Jordan_2017}</cite>, the evaluation of cross-modality image alignment, and quality control of images at each stage of processing.&nbsp;<b>On large datasets, especially longitudinal multisite consortium studies, these decisions cannot be reliably replicated because the timeframe of these studies is long, and the experts get fatigued.</b></div><div></div>