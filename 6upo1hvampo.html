<div>Finally, a deep learning model was trained on the brain slices to predict the XGBoost probability score. All brain slices were resized to 256 by 256 pixels and converted to 3 color channels (RGB). The data was split into 80%-10%-10% training-validation-test sets. The data was split such that all slices belonging to the same subject were grouped together, so that there wasn't any spillover across the training, validation, and test sets.&nbsp;We loaded the pretrained VGG16 network&nbsp;<cite class="ltx_cite raw v1">\cite{simonyan2014very}</cite> implemented in Keras&nbsp;<cite class="ltx_cite raw v1">\cite{chollet2015keras}</cite>, removed the top layer, and ran inference on all the data. The output of the VGG16 inference was then used to train  a final layer dense layer followed by a single node output layer with sigmoid activation. The training of the final layer was run for 50 epochs and the best model on the validation set was saved. We ran this model 10 separate times, each time with a different random initialization seed, in order to measure the variability of our ROC AUC on the test set.&nbsp;</div><div></div><div></div>