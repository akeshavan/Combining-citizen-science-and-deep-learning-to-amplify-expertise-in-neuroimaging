<div>Finally, a deep learning model was trained on the brain slices to predict the XGBoost probability score. All brain slices were resized to 256 by 256 pixels and converted to 3 color channels (RGB). We loaded the pretrained VGG16 network&nbsp;<cite class="ltx_cite raw v1">\cite{simonyan2014very}</cite> implemented in Keras&nbsp;<cite class="ltx_cite raw v1">\cite{chollet2015keras}</cite>, removed the top layer, and trained a final layer dense layer to single node output layer with sigmoid activation. This final layer was run for 50 epochs and the best model on the validation set was saved. We ran this model 10 separate times, each time with a different random initialization seed, in otd</div><div></div><div></div><ul><li>We used Keras () and the pretrained VGG16 netw</li><li>transfer learning</li><li>50 epochs, ran 10 times with different seed</li><li>on test set, ROC analysis against gold standard data in test set</li><li>ROC was 0.99.</li></ul><div></div><div></div><h1 data-label="795074" class="ltx_title_section">Acknowledgements</h1><div></div><div>We'd like to acknowledge the following people for fruitful discussions and contributions to the project. Dylan Nielson, Satra Ghosh and Dave Kennedy for the inspiration for braindr. Greg Kiar, for contributing badges to the braindr application. Chris Markiewicz, for discussions on application performance, and for application testing in the early stages. Katie Bottenhorn, Dave Kennedy, and Amanda Easson for quality controlling the gold standard dataset. Jamie Hanson, for sharing the MRIQC metrics. Chris Madan, for application testing and for discussions regarding QC standards. Arno Klein and Lei Ai, for providing us the segmented images from the HBN dataset. Tal Yarkoni and Alejandro de la Vega, for organizing a "code rodeo" for neuroimagers in Austin, TX, where the idea for braindr was born. Finally, we'd like to thank all the citizen scientists who swiped on braindr - we are very grateful for your contributions!</div>