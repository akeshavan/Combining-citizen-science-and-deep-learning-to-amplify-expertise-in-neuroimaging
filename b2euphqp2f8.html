<div>The distribution on Figure&nbsp;<span class="au-ref raw v1">\ref{358654}</span> A was bimodal, as expected, but the left peak (corresponding to failed slices) was shifted to the right. Because these were gold standard images, selected because neuroimaging experts who confidently passed or failed these images, we expected the left peak of the bimodal distribution to be at 0. This implied that some users were incorrectly passing images. To select the users who rated more similarly to the gold standard raters, we trained an XGBoost classifier&nbsp;<cite class="ltx_cite raw v1">\cite{chen2016xgboost}</cite> implemented in Python (<a href="http://xgboost.readthedocs.io/en/latest/python/python_intro.html">http://xgboost.readthedocs.io/en/latest/python/python_intro.html</a>) using the cross-validation functions from the scikit-learn Python library&nbsp;<cite class="ltx_cite raw v1">\cite{pedregosa2011scikit}</cite>. We trained the classifier on splits of various sizes of the data to test the dependence on training size (see Figure&nbsp;<span class="au-ref raw v1">\ref{908847}</span>A). Using the model trained on two-thirds of the data (n=670), we extracted the probability scores of the classifier on all 3609 slices in braindr (see Figure&nbsp;<span class="au-ref raw v1">\ref{908847}</span>B). The distribution of probability scores in Figure&nbsp; better matches our expectations of the data</div>