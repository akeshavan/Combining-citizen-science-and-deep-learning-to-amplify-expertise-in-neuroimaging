<div><b>“Big Data” in Neuroimaging is needed to answer important questions about the brain. But our standard lab protocols (“small data”) no longer work, because decisions made by experts are difficult to scale</b></div><li><div><b>Our proposed solution is to 1) start with a small, expertly labelled dataset, 2) amplify labels through citizen science via web-based tools, and 3) train machine learning on amplified labels to emulate expert decision making.</b></div></li><li><div><b>As a proof of concept, we developed a system to quality control over 700 T1-weighted images from the Healthy Brain Network.</b></div></li><li><div><b>An initial expertly labelled dataset (of 200 images) was amplified by citizen scientists to the entire dataset (724) with over 60,000 ratings through a simple web interface.</b></div></li><li><div><b>A deep learning algorithm was trained to predict data quality from the aggregate citizen scientist labels</b></div></li><li><div><b>In an ROC analysis on left out data, the deep learning network performed as well as a state-of-the-art, specialized algorithm (mriqc) for T1-weighted images, each with an area under the curve of 0.99. </b></div></li><li><div><b>Therefore, we assert that combining citizen science and deep learning can generalize and scale neuroimaging expert decision making; this is particularly important in the cases where specialized, automated tools do not already exist. </b></div></li><li><div><b>Finally, for an application, we explore how brain image quality relates to the replicability of the well established relationship between brain volumes and age over development.</b></div></li><div> goes here</div>